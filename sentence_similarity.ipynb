{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0ihlxS-lpUs"
      },
      "source": [
        "# Main Code\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.is_available()\n",
        "torch.cuda.get_device_name(0)"
      ],
      "metadata": {
        "id": "roMdZqRhfKzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BX5V6mTQltwS"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi -L"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AmolPRMHk3ww"
      },
      "outputs": [],
      "source": [
        "!python /content/drive/MyDrive/repos/dcase-2020-baseline/main.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w2jc3vUfnEEN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/repos/dcase-2020-baseline/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8tGAsw-Fop8s"
      },
      "outputs": [],
      "source": [
        "!pip install numba==0.48\n",
        "!pip install librosa==0.7.2\n",
        "!pip install numpy==1.19.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bic38HI6pczF"
      },
      "outputs": [],
      "source": [
        "!pip install mxnet-cu80"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "id": "yv6iUQ9J2xRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sentence Similarity\n"
      ],
      "metadata": {
        "id": "oiSDq44mtAdE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U sentence-transformers\n"
      ],
      "metadata": {
        "id": "QmS6X1L1s1XO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "model = SentenceTransformer('lighteternal/stsb-xlm-r-greek-transfer')\n",
        "\n",
        "sentences1 = ['Rain coming down on top of a roof, steadily.',\n",
        "             'Rain is hitting the top of a roof at a steady pace.',\n",
        "             'Water flowing in a mechanical water mill and dripping down onto some surface.',\n",
        "             'Water flows at a constant rate and also drips.',\n",
        "             'Water from a mechanical mill is flowing and dripping down onto a surface.']\n",
        "\n",
        "sentences2 = [\"βροχη πεφτει δυνατα\",\n",
        "             \"βροχη πεφτει δυνατα\",\n",
        "             \"βροχη πεφτει δυνατα\",\n",
        "             \"βροχη πεφτει δυνατα\",\n",
        "             \"βροχη πεφτει δυνατα\"]\n",
        "\n",
        "\n",
        "embeddings1 = model.encode(sentences1, convert_to_tensor=True)\n",
        "embeddings2 = model.encode(sentences2, convert_to_tensor=True)\n",
        "\n",
        "#Compute cosine-similarities (clone repo for util functions)\n",
        "from sentence_transformers import util\n",
        "cosine_scores = util.pytorch_cos_sim(embeddings1, embeddings2)\n",
        "\n",
        "#Output the pairs with their score\n",
        "for i in range(len(sentences1)):\n",
        "    print(\"{} \t\t {} \t\t Score: {:.4f}\".format(sentences1[i], sentences2[i], cosine_scores[i][i]))\n",
        "    \n",
        "#Outputs:\n",
        "#Το κινητό έπεσε και έσπασε. \t\t H πτώση κατέστρεψε τη συσκευή. \t\t Score: 0.6741\n",
        "#Το κινητό έπεσε και έσπασε. \t\t Το αυτοκίνητο έσπασε στα δυο. \t\t Score: 0.5067\n",
        "#Το κινητό έπεσε και έσπασε. \t\t Ο υπουργός έπεσε και έσπασε το πόδι του. \t\t Score: 0.4548\n"
      ],
      "metadata": {
        "id": "YucuUAnktId0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import pandas as pd\n",
        "model = SentenceTransformer('lighteternal/stsb-xlm-r-greek-transfer')\n",
        "\n",
        "full_file = pd.read_csv(r'/content/drive/MyDrive/generated_captions.csv',  encoding='utf-8-sig')\n",
        "\n",
        "print(full_file.shape)\n"
      ],
      "metadata": {
        "id": "u4mHcYTGyTN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import pandas as pd\n",
        "# print(full_file.iloc[3,0])\n",
        "file_extend = full_file\n",
        "print(file_extend.shape)\n",
        "# file_extend.insert(scores)\n",
        "print(file_extend.shape)\n",
        "# for i in range(full_file.shape[0]):\n",
        "#   print(full_file.iloc[i,0])\n",
        "list1 = []\n",
        "list2 = []\n",
        "list3 = []\n",
        "adder = 0\n",
        "# print(full_file.iloc[1,0])\n",
        "for i in range (full_file.shape[0]):\n",
        "  list1 = []\n",
        "  adder = 0 \n",
        "  mesosoros = 0\n",
        "\n",
        "  sentences1 = [full_file.iloc[i,2],\n",
        "               full_file.iloc[i,3],\n",
        "               full_file.iloc[i,4],\n",
        "               full_file.iloc[i,5],\n",
        "               full_file.iloc[i,6]]\n",
        "\n",
        "  sentences2 = [full_file.iloc[i,0],\n",
        "               full_file.iloc[i,0],\n",
        "               full_file.iloc[i,0],\n",
        "               full_file.iloc[i,0],\n",
        "               full_file.iloc[i,0]]\n",
        "\n",
        "\n",
        "  embeddings1 = model.encode(sentences1, convert_to_tensor=True)\n",
        "  embeddings2 = model.encode(sentences2, convert_to_tensor=True)\n",
        "\n",
        "  #Compute cosine-similarities (clone repo for util functions)\n",
        "  from sentence_transformers import util\n",
        "  cosine_scores = util.pytorch_cos_sim(embeddings1, embeddings2)\n",
        "\n",
        "  # for i in range(len(sentences1)):\n",
        "  #   print(\"{} \t\t {} \t\t Score: {:.4f}\".format(sentences1[i], sentences2[i], cosine_scores[i][i]))\n",
        "  for k in range(len(sentences1)):\n",
        "    # print(sentences1[k])\n",
        "    # print(sentences2[k])\n",
        "    # # list2.append(cosine_scores[k][k].format)\n",
        "    # print(\"{} \".format(cosine_scores[k][k]))\n",
        "    # print('score is ', cosine_scores[k][k])\n",
        "    list1.append(cosine_scores[k][k])\n",
        "  \n",
        "    list2.append(cosine_scores[k][k].cpu().detach().numpy())\n",
        "  print(list1)\n",
        "  max = 0 \n",
        "  for indx in range(len(list1)):\n",
        "    list1[indx]= list1[indx].item()\n",
        "    list1[indx] = round(list1[indx], 4)\n",
        "    #if (max < list1[indx]):  #for finding max\n",
        "      #max = list1[indx]      #\n",
        "  #list3.append(max)       #\n",
        "\n",
        "\n",
        "    adder = adder + list1[indx]  # for finding avg\n",
        "  mesosoros = adder/5 #\n",
        "  list3.append(mesosoros) #\n",
        "\n",
        "print(len(list1))\n",
        "print(mesosoros)\n",
        "print(list3)\n",
        "\n",
        "\n",
        "# print(type(cosine_scores))\n",
        "# print(cosine_scores.shape)\n",
        "# print(list1)\n",
        "\n",
        "# # for l in range (len(list1)):\n",
        "# #   list1[l] = list1[l].score_function\n",
        "\n",
        "# print (list1)\n",
        "# print(list2)\n",
        "# print(len(list1))\n",
        "# print(len(list2))\n",
        "\n",
        "\n",
        "\n",
        "# print(list1)"
      ],
      "metadata": {
        "id": "iI961louzDx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for avg\n",
        "# file_extend.insert(8, \"score\", list3)\n",
        "\n",
        "file_extend['score'] = list3\n",
        "\n"
      ],
      "metadata": {
        "id": "LhjDfj4u7MJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(list3))"
      ],
      "metadata": {
        "id": "OkN2AFfnwkmU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for max \n",
        "file_extend2 = full_file\n",
        "print(file_extend2.shape)\n",
        "file_extend2['max_score'] = list3\n",
        "print(file_extend2.shape)\n",
        "\n",
        "file_extend2.to_csv('final_with_max_scores.csv', encoding= 'utf-8')"
      ],
      "metadata": {
        "id": "2Y6vnxIvtLYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(file_extend.iloc[0,7])\n",
        "for i in range(file_extend.shape[0]):\n",
        "      file_extend.iloc[i,7] = round(file_extend.iloc[i,7], 4)\n"
      ],
      "metadata": {
        "id": "ysVRfVjj9qKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "good = 0\n",
        "for j in range(file_extend2.shape[0]):\n",
        "  if (file_extend2.iloc[j,8] >= 0.5):\n",
        "    good = good +1\n",
        "print(good)"
      ],
      "metadata": {
        "id": "ftClOn-c_ofB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_extend.to_csv('final_with_scores2.csv', encoding= 'utf-8')\n"
      ],
      "metadata": {
        "id": "vAawCQcw-AVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "a = file_extend['max_score']\n",
        "# Creating histogram\n",
        "fig, ax = plt.subplots(figsize =(10, 7))\n",
        "ax.hist(a, bins = [0,0.1 ,0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])\n",
        " \n",
        "# Adding extra features   \n",
        "plt.xlabel(\"max Sentence Similarity score\")\n",
        "plt.ylabel(\"number of generated captions\")\n",
        "plt.legend(legend)\n",
        "plt.title('Histogram of Sentence SImilarity Distribution')\n",
        "# Show plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bhwYqpD3ZgXa"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}